{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDjy7R9hGkcX"
      },
      "source": [
        "# 1. Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7aOv4iZzyG6m"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUnMBWN1QOyX"
      },
      "source": [
        "## 1.1 Packages\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kewzGbHwolnv"
      },
      "source": [
        "Reference:\n",
        "\n",
        "https://github.com/pyy0715/Neural-Collaborative-Filtering/blob/master/src/model.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install tensorboardX\n",
        "! pip install comet_ml --quiet\n",
        "! pip install tensorboardX --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10DT5c-_ySXE",
        "outputId": "7f8da211-61d6-4bfe-f924-fe40aff98d34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.8/dist-packages (2.5.1)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (3.19.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch packages\n",
        "import torch\n",
        "# Data Processing and Visualization\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "from scipy.sparse.linalg import svds\n",
        "from mpl_toolkits import mplot3d\n",
        "\n",
        "# Sklearn Packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Python package\n",
        "import re\n",
        "\n",
        "# IO Packages\n",
        "import os\n",
        "\n",
        "import comet_ml\n",
        "comet_ml.init(project_name='NCF_adversarial_baseline')\n",
        "\n",
        "import torchvision.utils as vutils\n",
        "import torchvision.models as models\n",
        "from torchvision import datasets\n",
        "from tensorboardX import SummaryWriter\n",
        "import datetime"
      ],
      "metadata": {
        "id": "TYP625QtyUnx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfdd64ea-38f3-46cf-8f1e-744975cc41a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "COMET INFO: Comet API key is valid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSF4yRkWQsXL"
      },
      "source": [
        "### Key: mJW6twxmHY1SOLeltflyLMbaH\n",
        "### Key: LKMVBJt1vZVGiUCt8cwgck50H"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7V3w5YvYN1F"
      },
      "source": [
        "## 1.2 Connect to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acD8_iIXYNg3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4616ae69-72a7-4bdb-dd42-53631d76cfe7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TF1PplZ5QY0A"
      },
      "source": [
        "## 1.3 Visualize in tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kd6tsSmiQhQZ"
      },
      "outputs": [],
      "source": [
        "# Helper function to display logged assets in the Comet UI\n",
        "def display(tab=None):\n",
        "  experiment = comet_ml.get_global_experiment()\n",
        "  experiment.display(tab=tab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycY00aQAHdGH"
      },
      "source": [
        "# 2. NCF model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuVWvH-yNwWJ"
      },
      "source": [
        "## config.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Juf3EPcVNrUA"
      },
      "outputs": [],
      "source": [
        "# DATA_URL = \"http://files.grouplens.org/datasets/movielens/ml-100k/u.data\"\n",
        "# MAIN_PATH = '/content/Neural-Collaborative-Filtering/src/Neural-Collaborative-Filtering'\n",
        "# DATA_PATH = MAIN_PATH + 'data/ml-1m/ratings.dat'\n",
        "MAIN_PATH = \"/content/drive/MyDrive/Recommender System Codes/\"\n",
        "DATA_PATH=\"/content/drive/MyDrive/Recommender System Codes/MovieLen1M/\"\n",
        "MODEL_PATH = MAIN_PATH + 'models/'\n",
        "MODEL = 'ml-1m_Neu_MF'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yA8B2uPrNzI_"
      },
      "source": [
        "## data_utils.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pc3Mm0xFN1jL"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import torch\n",
        "# import config \n",
        "\n",
        "class NCF_Data(object):\n",
        "\t\"\"\"\n",
        "\tConstruct Dataset for NCF\n",
        "\t\"\"\"\n",
        "\tdef __init__(self, args, ratings):\n",
        "\t\tself.ratings = ratings\n",
        "\t\tself.num_ng = args.num_ng\n",
        "\t\tself.num_ng_test = args.num_ng_test\n",
        "\t\tself.batch_size = args.batch_size\n",
        "# reindex \n",
        "\t\tself.preprocess_ratings = self._reindex(self.ratings)\n",
        "# all unique users and items in ratings.csv\n",
        "\t\tself.user_pool = set(self.ratings['user_id'].unique())\n",
        "\t\tself.item_pool = set(self.ratings['item_id'].unique())\n",
        "# split into train and test set, we should add a validation set\n",
        "\t\tself.train_ratings, self.test_ratings = self._leave_one_out(self.preprocess_ratings)\n",
        "# interacted items (positive samples?)\n",
        "\t\tself.negatives = self._negative_sampling(self.preprocess_ratings)\n",
        "\t\trandom.seed(args.seed)\n",
        "\t\n",
        "\tdef _reindex(self, ratings):\n",
        "\t\t\"\"\"\n",
        "\t\tProcess dataset to reindex userID and itemID, also set rating as binary feedback\n",
        "\t\t\"\"\"\n",
        "\t\tuser_list = list(ratings['user_id'].drop_duplicates())\n",
        "\t\tuser2id = {w: i for i, w in enumerate(user_list)}\n",
        "\n",
        "\t\titem_list = list(ratings['item_id'].drop_duplicates())\n",
        "\t\titem2id = {w: i for i, w in enumerate(item_list)}\n",
        "\n",
        "\t\tratings['user_id'] = ratings['user_id'].apply(lambda x: user2id[x])\n",
        "\t\tratings['item_id'] = ratings['item_id'].apply(lambda x: item2id[x])\n",
        "\t\tratings['rating'] = ratings['rating'].apply(lambda x: float(x > 0))\n",
        "\t\treturn ratings\n",
        "\n",
        "\tdef _leave_one_out(self, ratings):\n",
        "\t\t\"\"\"\n",
        "\t\tleave-one-out evaluation protocol in paper https://www.comp.nus.edu.sg/~xiangnan/papers/ncf.pdf\n",
        "\t\t\"\"\"\n",
        "\t\tratings['rank_latest'] = ratings.groupby(['user_id'])['timestamp'].rank(method='first', ascending=False)\n",
        "\t\ttest = ratings.loc[ratings['rank_latest'] == 1]\n",
        "\t\ttrain = ratings.loc[ratings['rank_latest'] > 1]\n",
        "\t\tassert train['user_id'].nunique()==test['user_id'].nunique(), 'Not Match Train User with Test User'\n",
        "\t\treturn train[['user_id', 'item_id', 'rating']], test[['user_id', 'item_id', 'rating']]\n",
        "\t\n",
        "\n",
        "\tdef _negative_sampling(self, ratings):\n",
        "\t\t# After grroupby, it becomes \"UserID, interacted items with THIS user\"\n",
        "\t\tinteract_status = (\n",
        "\t\t\tratings.groupby('user_id')['item_id']\n",
        "\t\t\t.apply(set)\n",
        "\t\t\t.reset_index()\n",
        "\t\t\t.rename(columns={'item_id': 'interacted_items'}))\n",
        "\t# negative_items refers to items that have no interaction with THIS user_id\n",
        "\t\tinteract_status['negative_items'] = interact_status['interacted_items'].apply(lambda x: self.item_pool - x)\n",
        "\t# negative_items refers to a random subset of negatives_items with THIS user\n",
        "\t\tinteract_status['negative_samples'] = interact_status['negative_items'].apply(lambda x: random.sample(x, self.num_ng_test))\n",
        "\t\treturn interact_status[['user_id', 'negative_items', 'negative_samples']]\n",
        "\n",
        "\tdef get_train_instance(self):\n",
        "\t\tusers, items, ratings = [], [], []\n",
        "\t\t# train_ratings is a n * m matrix, where 1 indicating interaction and 0 indicating negative items for each user \n",
        "\t\ttrain_ratings = pd.merge(self.train_ratings, self.negatives[['user_id', 'negative_items']], on='user_id')\n",
        "\t\t# train_ratings['negatives'] is a subset of negative items for each user \n",
        "\t\ttrain_ratings['negatives'] = train_ratings['negative_items'].apply(lambda x: random.sample(x, self.num_ng))\n",
        "\t\tfor row in train_ratings.itertuples():\n",
        "\t\t\tusers.append(int(row.user_id))\n",
        "\t\t\titems.append(int(row.item_id))\n",
        "\t\t\tratings.append(float(row.rating)) \n",
        "\t\t\tfor i in range(self.num_ng):\n",
        "\t\t\t\tusers.append(int(row.user_id))\n",
        "\t\t\t\titems.append(int(row.negatives[i]))\n",
        "\t\t\t\tratings.append(float(0))  # negative samples get 0 rating\n",
        "\t\tdataset = Rating_Datset(\n",
        "\t\t\tuser_list=users,\n",
        "\t\t\titem_list=items,\n",
        "\t\t\trating_list=ratings)\n",
        "\t\t# return a dataloader with full interacted items and self.num_ng number of negative items with rating = 0\n",
        "\t\treturn torch.utils.data.DataLoader(dataset, batch_size=self.batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "\t# same with get_train_instance\n",
        "\tdef get_test_instance(self):\n",
        "\t\tusers, items, ratings = [], [], []\n",
        "\t\ttest_ratings = pd.merge(self.test_ratings, self.negatives[['user_id', 'negative_samples']], on='user_id')\n",
        "\t\tfor row in test_ratings.itertuples():\n",
        "\t\t\tusers.append(int(row.user_id))\n",
        "\t\t\titems.append(int(row.item_id))\n",
        "\t\t\tratings.append(float(row.rating))\n",
        "\t\t\t# print('positive sample')\n",
        "\t\t\t# default 100 ng_items with 1 pos items at index 0\n",
        "\t\t\tfor i in getattr(row, 'negative_samples'):\n",
        "\t\t\t\tusers.append(int(row.user_id))\n",
        "\t\t\t\titems.append(int(i))\n",
        "\t\t\t\tratings.append(float(0))\n",
        "\t\t\t\t# print('negative sample')\n",
        "\t\tdataset = Rating_Datset(\n",
        "\t\t\tuser_list=users,\n",
        "\t\t\titem_list=items,\n",
        "\t\t\trating_list=ratings)\n",
        "\t\treturn torch.utils.data.DataLoader(dataset, batch_size=self.num_ng_test+1, shuffle=False, num_workers=4)\n",
        "\n",
        "\n",
        "class Rating_Datset(torch.utils.data.Dataset):\n",
        "\tdef __init__(self, user_list, item_list, rating_list):\n",
        "\t\tsuper(Rating_Datset, self).__init__()\n",
        "\t\tself.user_list = user_list\n",
        "\t\tself.item_list = item_list\n",
        "\t\tself.rating_list = rating_list\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.user_list)\n",
        "\n",
        "\tdef __getitem__(self, idx):\n",
        "\t\tuser = self.user_list[idx]\n",
        "\t\titem = self.item_list[idx]\n",
        "\t\trating = self.rating_list[idx]\n",
        "\t\t\n",
        "\t\treturn (\n",
        "\t\t\ttorch.tensor(user, dtype=torch.long),\n",
        "\t\t\ttorch.tensor(item, dtype=torch.long),\n",
        "\t\t\ttorch.tensor(rating, dtype=torch.float)\n",
        "\t\t\t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXrkEY7tGAOx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd6eca46-df94-42d1-f82c-62c4bfad4d2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      item_id                               title  \\\n",
            "0           1                    Toy Story (1995)   \n",
            "1           2                      Jumanji (1995)   \n",
            "2           3             Grumpier Old Men (1995)   \n",
            "3           4            Waiting to Exhale (1995)   \n",
            "4           5  Father of the Bride Part II (1995)   \n",
            "...       ...                                 ...   \n",
            "3878     3948             Meet the Parents (2000)   \n",
            "3879     3949          Requiem for a Dream (2000)   \n",
            "3880     3950                    Tigerland (2000)   \n",
            "3881     3951             Two Family House (2000)   \n",
            "3882     3952               Contender, The (2000)   \n",
            "\n",
            "                             genre  \n",
            "0      Animation|Children's|Comedy  \n",
            "1     Adventure|Children's|Fantasy  \n",
            "2                   Comedy|Romance  \n",
            "3                     Comedy|Drama  \n",
            "4                           Comedy  \n",
            "...                            ...  \n",
            "3878                        Comedy  \n",
            "3879                         Drama  \n",
            "3880                         Drama  \n",
            "3881                         Drama  \n",
            "3882                Drama|Thriller  \n",
            "\n",
            "[3883 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "movies = pd.read_csv(\n",
        "\tDATA_PATH+\"movies.dat\", \n",
        "\tsep=\"::\", \n",
        "\tnames = ['item_id', 'title', 'genre'], \n",
        "\tengine='python',\n",
        "\tencoding = \"ISO-8859-1\")\n",
        "print(movies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmbY4s6_GCPV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bc6e2b47-8815-49f6-f727-89ed0c342b77"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Drama|Thriller'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "movies.loc[movies['item_id'] == 3952, 'genre'].tolist()[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qiy7fGmKN53K"
      },
      "source": [
        "## evaluate.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNcPtSv3N5Ic"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import collections\n",
        "\n",
        "def hit(pos_item, pred_items):\n",
        "  if pos_item in pred_items:\n",
        "    return 1\n",
        "  return 0\n",
        "\n",
        "\n",
        "def ndcg(pos_item, pred_items):\n",
        "  if pos_item in pred_items:\n",
        "    index = pred_items.index(pos_item)\n",
        "    return np.reciprocal(np.log2(index+2))\n",
        "  return 0\n",
        "\n",
        "# Gini index to measure diversity of the recommended list\n",
        "def gini(pred_items):\n",
        "  gini_index = 1\n",
        "  k = len(pred_items)\n",
        "  genres = []\n",
        "  # genres is a list of lists\n",
        "  for item in pred_items:\n",
        "    genre = movies.loc[movies['item_id'] == item, 'genre'].tolist()\n",
        "    genres.append(genre)\n",
        "  # genres_lst is a list\n",
        "  genres_lst = [item for sublist in genres for item in sublist]\n",
        "  counter = collections.Counter(genres_lst)\n",
        "  frequency_lst = [counter[x]/k for x in sorted(counter.keys())]\n",
        "  for frequency in frequency_lst:\n",
        "    gini_index -= frequency**2\n",
        "  return gini_index\n",
        "\n",
        "# Entropy index to measure diversity of the recommended list\n",
        "def entropy(pred_items):\n",
        "  entropy_index = 0\n",
        "  k = len(pred_items)\n",
        "  genres = []\n",
        "  for item in pred_items:\n",
        "    genre = movies.loc[movies['item_id'] == item, 'genre'].tolist()\n",
        "    genres.append(genre)\n",
        "  genres_lst = [item for sublist in genres for item in sublist]\n",
        "  counter = collections.Counter(genres_lst)\n",
        "  frequency_lst = [counter[x]/k for x in sorted(counter.keys())]\n",
        "  for frequency in frequency_lst:\n",
        "    entropy_index = entropy_index + frequency * math.log(frequency,math.e)\n",
        "  return -entropy_index\n",
        "\n",
        "'''\n",
        "def coverage(pred_items):\n",
        "  k = len(pred_items)\n",
        "  item_len= len(items)\n",
        "  return k/item_len\n",
        "\n",
        "def personalization():\n",
        "  chech if the system recommends similiar items to all uers. Can we measure this if the available items are different for each user? \n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# def metrics(model, test_loader, top_k, device):\n",
        "#   HR, NDCG, GINI, Entropy  = [], [], [], []\n",
        "#   itemMetricCollection = torch.empty(len(test_loader),top_k)\n",
        "#   for i, (user, item, label) in enumerate(test_loader):\n",
        "#     user = user.to(device)\n",
        "#     item = item.to(device)\n",
        "#     #print('user:',user.shape,user)\n",
        "#     #print('item:',item.shape,item)\n",
        "\n",
        "#     predictions = model(user, item)\n",
        "#     _, indices = torch.topk(predictions, top_k)\n",
        "#     recommends = torch.take(\n",
        "#         item, indices).cpu().numpy().tolist()\n",
        "#     pos_item = item[0].item()\n",
        "#     #print('pos_item:',pos_item,'recommends:',recommends)\n",
        "#     # print(a) # leave one-out evaluation has only one item per user\n",
        "#     HR.append(hit(pos_item, recommends))\n",
        "#     NDCG.append(ndcg(pos_item, recommends))\n",
        "#     GINI.append(gini(recommends))\n",
        "#     Entropy.append(entropy(recommends))\n",
        "#   return np.mean(HR), np.mean(NDCG), np.mean(GINI), np.mean(Entropy)\n",
        "\n",
        "def itemMetric(recommendedCollection, average, top_k, diversity=False):\n",
        "  # TODO: popular vs long-tail items\n",
        "  \"\"\"\n",
        "  pred_items: 6040*10 list of the recommended items.\n",
        "  \"\"\"\n",
        "  # Figure out the genres \n",
        "  from collections import Counter\n",
        "  import numpy as np\n",
        "\n",
        "  recommendationDict = dict(Counter(recommendedCollection.flatten().cpu().numpy().tolist()))\n",
        "\n",
        "  itemAppearanceDict = dict(sorted(recommendationDict.items(), key = lambda kv:(-kv[1], kv[0])))\n",
        "\n",
        "  itemAppearanceList = np.array(list(recommendationDict.values()))\n",
        "\n",
        "  freq = itemAppearanceList/itemAppearanceList.sum()\n",
        "\n",
        "  # print(freq)\n",
        "\n",
        "  # Figure out the genres \n",
        "  if diversity:\n",
        "    return \n",
        "  # Do the statistics(个数)\n",
        "  else:\n",
        "    return sum(freq<average)/(6040*top_k)\n",
        "\n",
        "def metrics(model, test_loader, top_k, average, device):\n",
        "\n",
        "  HR, NDCG, GINI, Entropy, longTail, adv_weights_for_print  = [], [], [] ,[], [], None\n",
        "\n",
        "  itemMetricCollection = torch.empty(len(test_loader),top_k)\n",
        "\n",
        "  # Get the weights\n",
        "  # if adv_weights_for_print is not None:\n",
        "  #   print(\"adv_weights\",adv_weights_for_print)\n",
        "  #   print(\"weight_size\",adv_weights_for_print.size())\n",
        "\n",
        "  for i, (user, item, label) in enumerate(test_loader):\n",
        "    user = user.to(device)\n",
        "    item = item.to(device)\n",
        "\n",
        "    # item_indices, position information\n",
        "    predictions = model(user, item)\n",
        "    # print('predictions length',predictions.shape)\n",
        "    _, indices = torch.topk(predictions, top_k)\n",
        "\n",
        "    # Actual item_id, by taking out the indices\n",
        "    recommends = torch.take(item, indices).cpu().numpy().tolist()\n",
        "\n",
        "    # For itemMetric\n",
        "    itemMetricCollection[i]=torch.tensor(recommends)\n",
        "\n",
        "    # For the hit and NDCG\n",
        "    pos_item = item[0].item()\n",
        "\n",
        "    # User Centric Metrics\n",
        "    HR.append(hit(pos_item, recommends))\n",
        "    NDCG.append(ndcg(pos_item, recommends))\n",
        "    # GINI.append(gini(recommends))\n",
        "    # Entropy.append(entropy(recommends))\n",
        "    longTail.append(itemMetric(itemMetricCollection,average,top_k))\n",
        "    # print('recommends length',len(recommends),'longTail:',longTail)\n",
        "\n",
        "  # Handling item metrics\n",
        "  return np.mean(HR), np.mean(NDCG), np.mean(GINI), np.mean(Entropy), np.mean(longTail)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2K73W2rFN9Y2"
      },
      "source": [
        "##model.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlQRTRCFOJfx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Generalized_Matrix_Factorization(nn.Module):\n",
        "    def __init__(self, args, num_users, num_items):\n",
        "        super(Generalized_Matrix_Factorization, self).__init__()\n",
        "        self.num_users = num_users\n",
        "        self.num_items = num_items\n",
        "        self.factor_num = args.factor_num\n",
        "\n",
        "        self.embedding_user = nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.factor_num)\n",
        "        self.embedding_item = nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.factor_num)\n",
        "\n",
        "        self.affine_output = nn.Linear(in_features=self.factor_num, out_features=1)\n",
        "        # self.logistic = nn.Sigmoid()\n",
        "        self.logistic = nn.ReLU()\n",
        "\n",
        "    def forward(self, user_indices, item_indices):\n",
        "        user_embedding = self.embedding_user(user_indices)\n",
        "        item_embedding = self.embedding_item(item_indices)\n",
        "        # print('item_embedding',item_embedding)\n",
        "        # ELEMENT-WISE PRODUCT IN GMF\n",
        "        element_product = torch.mul(user_embedding, item_embedding)\n",
        "        logits = self.affine_output(element_product)\n",
        "        rating = self.logistic(logits)\n",
        "        return rating\n",
        "\n",
        "    def init_weight(self):\n",
        "        pass\n",
        "\n",
        "class Multi_Layer_Perceptron(nn.Module):\n",
        "    def __init__(self, args, num_users, num_items):\n",
        "        super(Multi_Layer_Perceptron, self).__init__()\n",
        "        self.num_users = num_users\n",
        "        self.num_items = num_items\n",
        "        self.factor_num = args.factor_num\n",
        "        self.layers = args.layers\n",
        "\n",
        "        self.embedding_user = nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.factor_num)\n",
        "        self.embedding_item = nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.factor_num)\n",
        "\n",
        "        self.fc_layers = nn.ModuleList()\n",
        "        for idx, (in_size, out_size) in enumerate(zip(self.layers[:-1], self.layers[1:])):\n",
        "            self.fc_layers.append(nn.Linear(in_size, out_size))\n",
        "\n",
        "        self.affine_output = nn.Linear(in_features=self.layers[-1], out_features=1)\n",
        "        self.logistic = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, user_indices, item_indices):\n",
        "        user_embedding = self.embedding_user(user_indices)\n",
        "        # print('user_embedding',user_embedding)\n",
        "        item_embedding = self.embedding_item(item_indices)\n",
        "        # print('item_embedding',item_embedding)\n",
        "        vector = torch.cat([user_embedding, item_embedding], dim=-1)  # the concat latent vector\n",
        "        for idx, _ in enumerate(range(len(self.fc_layers))):\n",
        "            vector = self.fc_layers[idx](vector)\n",
        "            vector = nn.ReLU()(vector)\n",
        "            # vector = nn.BatchNorm1d()(vector)\n",
        "            # vector = nn.Dropout(p=0.5)(vector)\n",
        "        logits = self.affine_output(vector)\n",
        "        rating = self.logistic(logits)\n",
        "        return rating\n",
        "\n",
        "    def init_weight(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "\n",
        "class NeuMF(nn.Module):\n",
        "    def __init__(self, args, num_users, num_items):\n",
        "        super(NeuMF, self).__init__()\n",
        "        self.num_users = num_users\n",
        "        self.num_items = num_items\n",
        "        self.factor_num_mf = args.factor_num\n",
        "        self.factor_num_mlp =  int(args.layers[0]/2)\n",
        "        self.layers = args.layers\n",
        "        self.dropout = args.dropout\n",
        "\n",
        "        self.embedding_user_mlp = nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.factor_num_mlp)\n",
        "        self.embedding_item_mlp = nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.factor_num_mlp)\n",
        "\n",
        "        self.embedding_user_mf = nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.factor_num_mf)\n",
        "        self.embedding_item_mf = nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.factor_num_mf)\n",
        "\n",
        "        self.fc_layers = nn.ModuleList()\n",
        "        for idx, (in_size, out_size) in enumerate(zip(args.layers[:-1], args.layers[1:])):\n",
        "            self.fc_layers.append(torch.nn.Linear(in_size, out_size))\n",
        "            self.fc_layers.append(nn.ReLU())\n",
        "\n",
        "        self.affine_output = nn.Linear(in_features=args.layers[-1] + self.factor_num_mf, out_features=1)\n",
        "        self.logistic = nn.Sigmoid()\n",
        "        self.init_weight()\n",
        "\n",
        "    def init_weight(self):\n",
        "        nn.init.normal_(self.embedding_user_mlp.weight, std=0.01)\n",
        "        nn.init.normal_(self.embedding_item_mlp.weight, std=0.01)\n",
        "        nn.init.normal_(self.embedding_user_mf.weight, std=0.01)\n",
        "        nn.init.normal_(self.embedding_item_mf.weight, std=0.01)\n",
        "        \n",
        "        for m in self.fc_layers:\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                \n",
        "        nn.init.xavier_uniform_(self.affine_output.weight)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, user_indices, item_indices):\n",
        "        user_embedding_mlp = self.embedding_user_mlp(user_indices)\n",
        "        item_embedding_mlp = self.embedding_item_mlp(item_indices)\n",
        "        # print('item_embedding_mlp',item_embedding_mlp,item_embedding_mlp.shape)\n",
        "\n",
        "        user_embedding_mf = self.embedding_user_mf(user_indices)\n",
        "        item_embedding_mf = self.embedding_item_mf(item_indices)\n",
        "        # print('item_embedding_mf',item_embedding_mf,item_embedding_mf.shape)\n",
        "\n",
        "        mlp_vector = torch.cat([user_embedding_mlp, item_embedding_mlp], dim=-1)  # the concat latent vector\n",
        "        mf_vector =torch.mul(user_embedding_mf, item_embedding_mf)\n",
        "\n",
        "        for idx, _ in enumerate(range(len(self.fc_layers))):\n",
        "            mlp_vector = self.fc_layers[idx](mlp_vector)\n",
        "\n",
        "        vector = torch.cat([mlp_vector, mf_vector], dim=-1)\n",
        "        logits = self.affine_output(vector)\n",
        "        rating = self.logistic(logits)\n",
        "        return rating.squeeze()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MciwzMJCOItU"
      },
      "source": [
        "## util.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQQEqVgbON7u"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np \n",
        "import torch\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqAOFKPoOPlj"
      },
      "source": [
        "## main.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PKDHgyCOQy4",
        "outputId": "e18ff49b-b752-41b9-a320-f6fc0e8c9806",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "COMET INFO: Comet API key is valid\n",
            "WARNING:tensorboardX.comet_utils:You have already created a comet                                         experiment manually, which might                                         cause clashes\n",
            "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: sklearn, torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
            "COMET INFO: ---------------------------\n",
            "COMET INFO: Comet.ml Experiment Summary\n",
            "COMET INFO: ---------------------------\n",
            "COMET INFO:   Data:\n",
            "COMET INFO:     display_summary_level : 1\n",
            "COMET INFO:     url                   : https://www.comet.com/richard1007/ncf-adversarial-baseline/691e23baaabd4fc1b8eda8318cf49597\n",
            "COMET INFO:   Metrics [count] (min, max):\n",
            "COMET INFO:     Perfomance/Entropy_10             : nan\n",
            "COMET INFO:     Perfomance/GINI_10                : nan\n",
            "COMET INFO:     Perfomance/HR_10 [3]              : (0.1576158940397351, 0.26887417218543047)\n",
            "COMET INFO:     Perfomance/LongtailProportion [3] : (0.014192645059427219, 0.24859546182184988)\n",
            "COMET INFO:     Perfomance/NDCG_10 [3]            : (0.0765837722151973, 0.15101506610517212)\n",
            "COMET INFO:     loss_primary [67254]              : (0.3513230085372925, 0.692193865776062)\n",
            "COMET INFO:   Others:\n",
            "COMET INFO:     Created from : tensorboardX\n",
            "COMET INFO:   Uploads:\n",
            "COMET INFO:     environment details : 1\n",
            "COMET INFO:     filename            : 1\n",
            "COMET INFO:     installed packages  : 1\n",
            "COMET INFO:     notebook            : 2\n",
            "COMET INFO:     os packages         : 1\n",
            "COMET INFO:     source_code         : 1\n",
            "COMET INFO: ---------------------------\n",
            "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: sklearn, torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
            "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "COMET ERROR: Failed to calculate active processors count. Fall back to default CPU count 1\n",
            "COMET INFO: Couldn't find a Git repository in '/content' nor in any parent directory. You can override where Comet is looking for a Git Patch by setting the configuration `COMET_GIT_DIRECTORY`\n",
            "COMET INFO: Experiment is live on comet.com https://www.comet.com/kaixinmao2000/ncf-adversarial-baseline/f5234509d0d14ba480cbbecce4aa89f1\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n",
            "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The time elapse of epoch 001 is: 00: 10: 46\n",
            "HR: 0.089\t NDCG: 0.038 Longtail: 0.247 \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n",
            "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The time elapse of epoch 002 is: 00: 06: 12\n",
            "HR: 0.097\t NDCG: 0.042 Longtail: 0.022 \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n",
            "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The time elapse of epoch 003 is: 00: 06: 10\n",
            "HR: 0.110\t NDCG: 0.050 Longtail: 0.023 \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n",
            "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The time elapse of epoch 004 is: 00: 06: 07\n",
            "HR: 0.130\t NDCG: 0.060 Longtail: 0.022 \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n",
            "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The time elapse of epoch 005 is: 00: 06: 07\n",
            "HR: 0.150\t NDCG: 0.071 Longtail: 0.020 \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n",
            "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The time elapse of epoch 006 is: 00: 06: 02\n",
            "HR: 0.176\t NDCG: 0.085 Longtail: 0.019 \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n",
            "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The time elapse of epoch 007 is: 00: 05: 56\n",
            "HR: 0.201\t NDCG: 0.096 Longtail: 0.017 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n",
            "WARNING:tensorboardX.x2num:NaN or Inf found in input tensor.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The time elapse of epoch 008 is: 00: 05: 51\n",
            "HR: 0.230\t NDCG: 0.117 Longtail: 0.016 \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "# import model \n",
        "# import config \n",
        "# import util\n",
        "# import data_utils\n",
        "# import evaluate\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--seed\", \n",
        "\ttype=int, \n",
        "\tdefault=42, \n",
        "\thelp=\"Seed\")\n",
        "parser.add_argument(\"--lr\", \n",
        "\ttype=float, \n",
        "\tdefault=0.001, \n",
        "\thelp=\"learning rate\")\n",
        "parser.add_argument(\"--dropout\", \n",
        "\ttype=float,\n",
        "\tdefault=0.2,  \n",
        "\thelp=\"dropout rate\")\n",
        "parser.add_argument(\"--batch_size\", \n",
        "\ttype=int, \n",
        "\tdefault=256, \n",
        "\thelp=\"batch size for training\")\n",
        "parser.add_argument(\"--epochs\", \n",
        "\ttype=int,\n",
        "\tdefault=15,  \n",
        "\thelp=\"training epoches\")\n",
        "parser.add_argument(\"--top_k\", \n",
        "\ttype=int, \n",
        "\tdefault=10, \n",
        "\thelp=\"compute metrics@top_k\")\n",
        "parser.add_argument(\"--factor_num\", \n",
        "\ttype=int,\n",
        "\tdefault=32, \n",
        "\thelp=\"predictive factors numbers in the model\")\n",
        "parser.add_argument(\"--layers\",\n",
        "    nargs='+', \n",
        "    default=[64,32,16,8],\n",
        "\t\t# default=[16,8],\n",
        "    help=\"MLP layers. Note that the first layer is the concatenation of user and item embeddings. So layers[0]/2 is the embedding size.\")\n",
        "parser.add_argument(\"--num_ng\", \n",
        "\ttype=int,\n",
        "\tdefault=4, \n",
        "\thelp=\"Number of negative samples for training set\")\n",
        "# default: 100 negative items with 1 positive items\n",
        "parser.add_argument(\"--num_ng_test\", \n",
        "\ttype=int,\n",
        "\tdefault=100, \n",
        "\thelp=\"Number of negative samples for test set\")\n",
        "parser.add_argument(\"--out\", \n",
        "\tdefault=True,\n",
        "\thelp=\"save model or not\")\n",
        "\n",
        "# set device and parameters\n",
        "# args = parser.parse_args() \n",
        "# Use this line for jupyter notebook\n",
        "args, unknown = parser.parse_known_args()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "writer = SummaryWriter(comet_config={\"disabled\": False})\n",
        "\n",
        "# seed for Reproducibility\n",
        "# util.seed_everything(args.seed)\n",
        "#seed_everything(args.seed)\n",
        "\n",
        "# load data\n",
        "# user_data = pd.read_csv(DATA_PATH+\"users.dat\", sep = \"::\", header=None, names=['UserID', 'Gender', 'Age', 'Occupation', 'Zip-code'])\n",
        "# movie_data = pd.read_csv(DATA_PATH+\"movies.dat\", sep = \"::\", header=None, encoding =\"latin-1\", names=['MovieID', 'Title', 'Genres'])\n",
        "# rating_data = pd.read_csv(DATA_PATH+\"ratings.dat\", sep = \"::\", header=None, names=['UserID', 'MovieID', 'Rating', 'Timestamp'])\n",
        "\n",
        "\n",
        "ml_1m = pd.read_csv(\n",
        "\tDATA_PATH+\"ratings.dat\", \n",
        "\tsep=\"::\", \n",
        "\tnames = ['user_id', 'item_id', 'rating', 'timestamp'], \n",
        "\tengine='python')\n",
        "\n",
        "movies = pd.read_csv(\n",
        "\tDATA_PATH+\"movies.dat\", \n",
        "\tsep=\"::\", \n",
        "\tnames = ['item_id', 'title', 'genre'], \n",
        "\tengine='python',\n",
        "\tencoding = \"ISO-8859-1\")\n",
        "\n",
        "# set the num_users, items\n",
        "num_users = ml_1m['user_id'].nunique()+1\n",
        "num_items = ml_1m['item_id'].nunique()+1\n",
        "\n",
        "# construct the train and test datasets\n",
        "data = NCF_Data(args, ml_1m)\n",
        "\n",
        "train_loader =data.get_train_instance()\n",
        "test_loader =data.get_test_instance()\n",
        "\n",
        "# set model and loss, optimizer\n",
        "model = NeuMF(args, num_users, num_items)\n",
        "model = model.to(device)\n",
        "loss_function = nn.BCELoss()\n",
        "# loss_function = nn.HingeEmbeddingLoss()\n",
        "average= num_items / len(ml_1m)\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr)\n",
        "# optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
        "\n",
        "# train, evaluation\n",
        "best_hr = 0\n",
        "for epoch in range(1, args.epochs+1):\n",
        "\tmodel.train() # Enable dropout (if have).\n",
        "\tstart_time = time.time()\n",
        "\n",
        "\tfor user, item, label in train_loader:\n",
        "\t\tuser = user.to(device)\n",
        "\t\titem = item.to(device)\n",
        "\t\t# print('item,'item)\n",
        "\t\tlabel = label.to(device)\n",
        "\n",
        "\t\toptimizer.zero_grad()\n",
        "\t\tprediction = model(user, item)\n",
        "\t\tloss_primary = loss_function(prediction, label) \n",
        "\t\t# print('prediction',prediction,'loss_primary',loss_primary)\n",
        "\t\t# loss_primary *= w.detach()\n",
        "\t\tloss_primary.backward()\n",
        "\t\t# optimize based on primary loss \n",
        "\t\toptimizer.step()\n",
        "\t\twriter.add_scalar('loss_primary', loss_primary.item(), epoch)\n",
        "\t\n",
        "\tmodel.eval()\n",
        "\t# itemAppearanceDict = metricsItem(model, test_loader, args.top_k, device)\n",
        "\t# print(itemAppreanceDict)\n",
        "\n",
        "\tHR, NDCG, GINI, Entropy, Longtail  = metrics(model, test_loader, args.top_k, average, device)\n",
        "\t# writer.add_scalar('Long-tail proportion', itemAppearanceDict, epoch)\n",
        "\twriter.add_scalar('Perfomance/HR@10', HR, epoch)\n",
        "\twriter.add_scalar('Perfomance/NDCG@10', NDCG, epoch)\n",
        "\twriter.add_scalar('Perfomance/GINI@10', GINI, epoch)\n",
        "\twriter.add_scalar('Perfomance/Entropy@10', Entropy, epoch)\n",
        "\twriter.add_scalar('Perfomance/LongtailProportion', Longtail, epoch)\n",
        "\t# itemAppearanceDict = metricsItem(model, test_loader, args.top_k, device)\n",
        "\t# print('itemAppearanceDict',itemAppearanceDict)\n",
        "\n",
        "\telapsed_time = time.time() - start_time\n",
        "\tprint(\"The time elapse of epoch {:03d}\".format(epoch) + \" is: \" + \n",
        "\t\t\ttime.strftime(\"%H: %M: %S\", time.gmtime(elapsed_time)))\n",
        "\t#print(\"HR: {:.3f}\\t NDCG: {:.3f} GINI: {:.3f}  Entropy: {:.3f} Longtail: {:.3f} \".format(np.mean(HR), np.mean(NDCG), np.mean(GINI), np.mean(Entropy),np.mean(Longtail)))\n",
        "\tprint(\"HR: {:.3f}\\t NDCG: {:.3f} Longtail: {:.3f} \".format(np.mean(HR), np.mean(NDCG),np.mean(Longtail)))\n",
        "\tif HR > best_hr:\n",
        "\t\tbest_hr, best_ndcg, best_epoch = HR, NDCG, epoch\n",
        "\t\tif args.out:\n",
        "\t\t\tif not os.path.exists(MODEL_PATH):\n",
        "\t\t\t\tos.mkdir(MODEL_PATH)\n",
        "\t\t\ttorch.save(model, \n",
        "\t\t\t\t'{}{}.pth'.format(MODEL_PATH, MODEL))\n",
        "\n",
        "writer.close()\n",
        "print(\"End. Best epoch {:03d}: HR = {:.3f}, NDCG = {:.3f}\".format(\n",
        "\t\t\t\t\t\t\t\t\tbest_epoch, best_hr, best_ndcg))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}